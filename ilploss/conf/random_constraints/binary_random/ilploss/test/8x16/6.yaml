seed_everything: 42

data:
  class_path: src.CombOptNet.src.datasets.BaseDataModule
  init_args:
    data_path: src/CombOptNet/data/binary_random/16_dim/8_const/6/dataset.pt
    splits:
      train: 1500
      val: 100
      test: 1000
    num_validate_train: 100
    batch_sizes:
      train: 10
      val: 100
      test: 1000
    num_workers: 4

model:
  class_path: src.CombOptNet.src.models.DecoderFreeModel
  init_args:
    x_key: x
    y_key: y

    core:
      class_path: src.cores.SolverFreeCore
      init_args:
        encoder:
          class_path: src.CombOptNet.src.encoders.DisjointEncoder
          init_args:
            ab_encoders:
              - class_path: src.CombOptNet.src.encoders.StaticABEncoder
                init_args:
                  num_vars: 16
                  num_constrs: 16
                  init_a:
                    class_path: torch.nn.init.uniform_
                    init_args:
                      a: -0.5
                      b: 0.5
                  init_r:
                    class_path: torch.nn.init.constant_
                    init_args:
                      val: 0.2
                  init_o:
                    class_path: torch.nn.init.uniform_
                    init_args:
                      a: 0.25
                      b: 0.75

            c_encoder:
              class_path: src.CombOptNet.src.encoders.IdentityCEncoder

        known_ab_encoder:
          class_path: src.encoders.LUToABEncoder
          init_args:
            lu_encoder:
              class_path: src.encoders.StaticLUEncoder
              init_args:
                num_vars: 16
                lb: 0.0
                ub: 1.0

        sampler:
          class_path: src.samplers.SamplerList
          init_args:
            samplers:
              - class_path: src.samplers.BitNbrSampler

              - class_path: src.samplers.BitKHopSampler
                init_args:
                  num_hops: 2
                  num_samples: 16

              - class_path: src.samplers.BitKHopSampler
                init_args:
                  num_hops: 3
                  num_samples: 16

              - class_path: src.samplers.BitKHopSampler
                init_args:
                  num_hops: 4
                  num_samples: 16

              - class_path: src.samplers.RandIntNbrWrapper
                init_args:
                  sampler:
                    class_path: src.samplers.ProjSampler

        criterion:
          class_path: src.losses.ILPLoss
          init_args:
            balancer:
              class_path: src.losses.CoVBalancer
              init_args:
                num_losses: 3

            pos_param: 0.01
            neg_param: 0.01


    solver:
      class_path: src.CombOptNet.src.ilp.CombOptNet
      init_args:
        vtype: B
        env:
          class_path: gurobi.Env
          init_args:
            params:
              OutputFlag: 0
        num_workers: 100

    hint: gold

    optimizer:
      class_path: torch.optim.AdamW

    lr_scheduler:
      class_path: torch.optim.lr_scheduler.CyclicLR
      init_args:
        base_lr: 0.0
        max_lr: 1.0e-3
        step_size_up: 1500
        cycle_momentum: false
      config:
        interval: step

    schedulers:
      temp:
        class_path: torch.optim.lr_scheduler.ReduceLROnPlateau
        init_args:
          mode: max
          factor: 0.1
          patience: 4
        config:
          monitor: val/acc/idv
          interval: epoch
          frequency: 20
        init: 1.0

trainer:
  max_epochs: 1_000_000
  callbacks:
    - class_path: src.callbacks.Timer
    - class_path: src.callbacks.CustomLogging
      init_args:
        rel_filename: training_stats.json
        global_filename: results/binary_random.json
    - class_path: pytorch_lightning.callbacks.Timer
      init_args:
        duration: 01:00:00:00
        interval: step
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        monitor: val/acc/idv
        patience: 20
        mode: max
        stopping_threshold: 0.999_999
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val/acc/idv
        mode: max
        save_weights_only: true
        filename: best
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        save_last: true
        train_time_interval: 0:15:0
        save_on_train_epoch_end: true

  gpus: 0
  num_sanity_val_steps: 0

  logger:
    class_path: pytorch_lightning.loggers.CSVLogger
    init_args:
      save_dir: runs/neurips
      name: binary_random/ilploss/8x16/6

  log_every_n_steps: 50
  check_val_every_n_epoch: 20

test_only: 1
