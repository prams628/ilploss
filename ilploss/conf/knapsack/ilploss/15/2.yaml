# env vars: seed=2, items=15

seed_everything: 2

data:
  class_path: src.datasets.KnapsackDataModule
  init_args:
    data_path: data/knapsack/15.pt
    splits:
      train: 4400
      val: 100
      test: 500
    num_validate_train: 100
    batch_sizes:
      train: 40
      test: 100
      val: 100
    num_workers: 4


model:
  class_path: src.CombOptNet.src.models.DecoderFreeModel
  init_args:
    reset_on_temp_change: true
    x_key: x
    y_key: y
    core:
      class_path: src.cores.SolverFreeCore
      init_args:
        encoder:
          class_path: src.encoders.KnapsackEncoder
          init_args:
            backbone_module_params:
              hidden_layer_size: 512
              num_constraints: 4
              embed_dim: 4096
              knapsack_capacity: 1.0
              weight_min: 0.0
              weight_max: 1.0
              cost_min: 0.0
              cost_max: 1.0
              output_nonlinearity: 'identity'

        known_ab_encoder:
          class_path: src.encoders.LUToABEncoder
          init_args:
            lu_encoder:
              class_path: src.encoders.StaticLUEncoder
              init_args:
                num_vars: 15
                lb: -0.5
                ub: 1.5

        sampler:
          class_path: src.samplers.SamplerList
          init_args:
            samplers:
              - class_path: src.samplers.BitNbrSampler

              - class_path: src.samplers.BitKHopSampler
                init_args:
                  num_hops: 2
                  num_samples: 15

              - class_path: src.samplers.BitKHopSampler
                init_args:
                  num_hops: 3
                  num_samples: 15

              - class_path: src.samplers.BitKHopSampler
                init_args:
                  num_hops: 4
                  num_samples: 15

              - class_path: src.samplers.RandIntNbrWrapper
                init_args:
                  sampler:
                    class_path: src.samplers.ProjSampler

              - class_path: src.samplers.BatchSampler

        criterion:
          class_path: src.losses.ILPLoss
          init_args:
            balancer:
              class_path: src.losses.CoVBalancer
              init_args:
                num_losses: 3

            pos_param: 0.01
            neg_param: 0.01

    solver:
      class_path: src.CombOptNet.src.ilp.CombOptNet
      init_args:
        vtype: 'I'
        env:
          class_path: gurobi.Env
          init_args:
            params:
              OutputFlag: 0
        num_workers: 10
        show_tqdm: true

    optimizer:
      class_path: torch.optim.AdamW
      init_args:
        weight_decay: 0.0
      custom:
        ".*backbone_module.*":
          weight_decay: 0.01

    lr_scheduler:
      class_path: torch.optim.lr_scheduler.CyclicLR
      init_args:
        base_lr: 0.0
        max_lr: 5.0e-4
        step_size_up: 440
        cycle_momentum: false
      config:
        interval: step

    schedulers:
      temp:
        class_path: torch.optim.lr_scheduler.ReduceLROnPlateau
        init_args:
          mode: max
          factor: 0.1
          patience: 4
          cooldown: 4
        config:
          monitor: val/acc/all
          interval: epoch
          frequency: 8
        init: 1.0

trainer:
  max_epochs: 1_000_000
  callbacks:
    - class_path: src.callbacks.Timer
    - class_path: src.callbacks.CustomLogging
      init_args:
        rel_filename: training_stats.json
        global_filename: results/knapsack_binary_ilploss_15.json
    - class_path: pytorch_lightning.callbacks.Timer
      init_args:
        duration: 00:12:00:00
        interval: step
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        monitor: val/acc/all
        patience: 100
        mode: max
        stopping_threshold: 0.999_999
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val/acc/all
        mode: max
        save_weights_only: true
        filename: best
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        save_last: true
        train_time_interval: 0:15:0
        save_on_train_epoch_end: true

  gpus: 1
  auto_select_gpus: true
  precision: 16
  num_sanity_val_steps: 0

  gradient_clip_val: 0.01

  logger:
    class_path: pytorch_lightning.loggers.TensorBoardLogger
    init_args:
      save_dir: runs/neurips
      name: knapsack/binary/ilploss/items_15/seed_2
      default_hp_metric: false

  log_every_n_steps: 440
  check_val_every_n_epoch: 8

  deterministic: false
