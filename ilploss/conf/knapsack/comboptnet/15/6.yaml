# env vars: seed=6, items=15, w_min=0.1, w_max=0.24

seed_everything: 6

data:
  class_path: src.datasets.KnapsackDataModule
  init_args:
    data_path: data/knapsack/15.pt
    splits:
      train: 4400
      val: 100
      test: 500
    num_validate_train: 100
    batch_sizes:
      train: 8
      test: 100
      val: 100
    num_workers: 4


model:
  class_path: src.CombOptNet.src.models.DecoderFreeModel
  init_args:
    x_key: x
    y_key: y
    core:
      class_path: src.CombOptNet.src.cores.SolverCore
      init_args:
        encoder:
          class_path: src.encoders.KnapsackEncoder
          init_args:
            backbone_module_params:
              hidden_layer_size: 512
              num_constraints: 4
              embed_dim: 4096
              knapsack_capacity: 1.0
              weight_min: 0.1
              weight_max: 0.24
              cost_min: 0.10
              cost_max: 0.45
              output_nonlinearity: 'sigmoid'

        known_ab_encoder:
          class_path: src.encoders.LUToABEncoder
          init_args:
            lu_encoder:
              class_path: src.encoders.StaticLUEncoder
              init_args:
                num_vars: 15
                lb: -0.5
                ub: 1.5

        solver:
          class_path: src.CombOptNet.ext.wrap.CombOptNet
          init_args:
            lb: 0.0
            ub: 1.0
            tau: 0.5
            num_threads: 1

        criterion:
          class_path: torch.nn.L1Loss

    solver:
      class_path: src.CombOptNet.src.ilp.CombOptNet
      init_args:
        vtype: 'I'
        env:
          class_path: gurobi.Env
          init_args:
            params:
              OutputFlag: 0
        num_workers: 10
        show_tqdm: true

    optimizer:
      class_path: torch.optim.AdamW
      init_args:
        lr: 5.0e-4
        weight_decay: 0.0
      custom:
        ".*backbone_module.*":
          weight_decay: 0.01

    lr_scheduler:
      class_path: torch.optim.lr_scheduler.ExponentialLR
      init_args:
        gamma: 1.0

trainer:
  max_epochs: 1_000_000
  callbacks:
    - class_path: src.callbacks.Timer
    - class_path: src.callbacks.CustomLogging
      init_args:
        rel_filename: training_stats.json
        global_filename: results/knapsack_binary_comboptnet_15.json
    - class_path: pytorch_lightning.callbacks.Timer
      init_args:
        duration: 00:12:00:00
        interval: step
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        monitor: val/acc/all
        patience: 10
        mode: max
        stopping_threshold: 0.999_999
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val/acc/all
        mode: max
        save_weights_only: true
        filename: best
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        save_last: true
        train_time_interval: 0:15:0
        save_on_train_epoch_end: true

  gpus: 1
  auto_select_gpus: true
  precision: 16
  num_sanity_val_steps: 0

  logger:
    class_path: pytorch_lightning.loggers.TensorBoardLogger
    init_args:
      save_dir: runs/neurips
      name: knapsack/binary/comboptnet/items_15/seed_6
      default_hp_metric: false

  log_every_n_steps: 440
  check_val_every_n_epoch: 1

  deterministic: false
